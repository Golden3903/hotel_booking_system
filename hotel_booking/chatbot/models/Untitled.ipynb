{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c542415c-745d-4a41-a94d-8548b37f4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\lib\\site-packages (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from h5py) (2.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b01086a-06ec-4717-9154-af1f8db1891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-lookups-data in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy-lookups-data) (75.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy-lookups-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232fd269-8940-4df0-a03d-bf65725d2abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25396\\329798100.py\", line 17, in <module>\n",
      "    nlp = spacy.load(\"en_core_web_sm\")  # or \"en_core_web_trf\" for transformer-based models\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py\", line 51, in load\n",
      "    return util.load_model(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 465, in load_model\n",
      "    return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 501, in load_model_from_package\n",
      "    return cls.load(vocab=vocab, disable=disable, enable=enable, exclude=exclude, config=config)  # type: ignore[attr-defined]\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\en_core_web_sm\\__init__.py\", line 10, in load\n",
      "    return load_model_from_init_py(__file__, **overrides)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 682, in load_model_from_init_py\n",
      "    return load_model_from_path(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 539, in load_model_from_path\n",
      "    nlp = load_model_from_config(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 587, in load_model_from_config\n",
      "    nlp = lang_cls.from_config(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\language.py\", line 1858, in from_config\n",
      "    nlp = lang_cls(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\language.py\", line 191, in __init__\n",
      "    util.registry._entry_point_factories.get_all()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\catalogue\\__init__.py\", line 110, in get_all\n",
      "    result.update(self.get_entry_points())\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\catalogue\\__init__.py\", line 125, in get_entry_points\n",
      "    result[entry_point.name] = entry_point.load()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\metadata\\__init__.py\", line 205, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\__init__.py\", line 1, in <module>\n",
      "    from . import architectures\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\architectures.py\", line 6, in <module>\n",
      "    from .layers import TransformerModel, TransformerListener\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\layers\\__init__.py\", line 1, in <module>\n",
      "    from .listener import TransformerListener\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\layers\\listener.py\", line 5, in <module>\n",
      "    from ..data_classes import TransformerData\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\data_classes.py\", line 13, in <module>\n",
      "    from .util import transpose_list\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\util.py\", line 4, in <module>\n",
      "    from transformers import AutoModel, AutoTokenizer\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1852, in __getattr__\n",
      "    value = getattr(module, name)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1851, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1863, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 40, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1851, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1863, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 53, in <module>\n",
      "    from .candidate_generator import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py\", line 26, in <module>\n",
      "    from sklearn.metrics import roc_curve\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25396\\329798100.py\", line 17, in <module>\n",
      "    nlp = spacy.load(\"en_core_web_sm\")  # or \"en_core_web_trf\" for transformer-based models\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py\", line 51, in load\n",
      "    return util.load_model(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 465, in load_model\n",
      "    return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 501, in load_model_from_package\n",
      "    return cls.load(vocab=vocab, disable=disable, enable=enable, exclude=exclude, config=config)  # type: ignore[attr-defined]\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\en_core_web_sm\\__init__.py\", line 10, in load\n",
      "    return load_model_from_init_py(__file__, **overrides)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 682, in load_model_from_init_py\n",
      "    return load_model_from_path(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 539, in load_model_from_path\n",
      "    nlp = load_model_from_config(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\util.py\", line 587, in load_model_from_config\n",
      "    nlp = lang_cls.from_config(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\language.py\", line 1858, in from_config\n",
      "    nlp = lang_cls(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\language.py\", line 191, in __init__\n",
      "    util.registry._entry_point_factories.get_all()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\catalogue\\__init__.py\", line 110, in get_all\n",
      "    result.update(self.get_entry_points())\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\catalogue\\__init__.py\", line 125, in get_entry_points\n",
      "    result[entry_point.name] = entry_point.load()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\metadata\\__init__.py\", line 205, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\__init__.py\", line 1, in <module>\n",
      "    from . import architectures\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\architectures.py\", line 6, in <module>\n",
      "    from .layers import TransformerModel, TransformerListener\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\layers\\__init__.py\", line 1, in <module>\n",
      "    from .listener import TransformerListener\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\layers\\listener.py\", line 5, in <module>\n",
      "    from ..data_classes import TransformerData\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\data_classes.py\", line 13, in <module>\n",
      "    from .util import transpose_list\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy_transformers\\util.py\", line 4, in <module>\n",
      "    from transformers import AutoModel, AutoTokenizer\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1852, in __getattr__\n",
      "    value = getattr(module, name)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1851, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1863, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 40, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1851, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1863, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 53, in <module>\n",
      "    from .candidate_generator import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py\", line 26, in <module>\n",
      "    from sklearn.metrics import roc_curve\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 1.2471711486577988}\n",
      "Epoch 2 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 1.1117966026067734}\n",
      "Epoch 3 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.7458997815847397}\n",
      "Epoch 4 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.28579967841506004}\n",
      "Epoch 5 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.09553767857141793}\n",
      "Epoch 6 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.021732621011324227}\n",
      "Epoch 7 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.003707325719005894}\n",
      "Epoch 8 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.0016380395491069066}\n",
      "Epoch 9 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.002260660795741387}\n",
      "Epoch 10 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 1.0361486737053838e-05}\n",
      "Input: I want to cancel my reservation.\n",
      " → Predicted Intent: cancel_booking\n",
      "\n",
      "Input: How much is a deluxe room?\n",
      " → Predicted Intent: ask_price\n",
      "\n",
      "Input: Can I book a suite for Saturday?\n",
      " → Predicted Intent: book_room\n",
      "\n",
      "Input: Hey, is there anything available tonight?\n",
      " → Predicted Intent: check_availability\n",
      "\n",
      "Input: Hi!\n",
      " → Predicted Intent: greet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Load training data\n",
    "with open('hotel_booking_intents_expanded.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "train_data = []\n",
    "for intent in data['intents']:\n",
    "    for text in intent['examples']:\n",
    "        train_data.append((text, {'cats': {intent['intent']: 1}}))\n",
    "\n",
    "# Load spaCy model (base or transformer model)\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # or \"en_core_web_trf\" for transformer-based models\n",
    "\n",
    "# Check if 'textcat' pipe exists, if yes, remove it\n",
    "if \"textcat\" in nlp.pipe_names:\n",
    "    nlp.remove_pipe(\"textcat\")\n",
    "\n",
    "# Add text classification pipeline (no extra params like architecture)\n",
    "textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "\n",
    "# Add intent labels to the 'textcat' component\n",
    "for intent in data['intents']:\n",
    "    textcat.add_label(intent['intent'])\n",
    "\n",
    "# Convert to spaCy Examples\n",
    "train_examples = []\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    train_examples.append(example)\n",
    "\n",
    "# Begin training\n",
    "nlp.initialize(lambda: train_examples)\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_examples)\n",
    "    losses = {}\n",
    "    batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.5))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, drop=0.1, losses=losses)\n",
    "    print(f\"Epoch {epoch+1} Loss: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"hotel_intent_classifier\")\n",
    "\n",
    "# Test with sample inputs\n",
    "test_texts = [\n",
    "    \"I want to cancel my reservation.\",\n",
    "    \"How much is a deluxe room?\",\n",
    "    \"Can I book a suite for Saturday?\",\n",
    "    \"Hey, is there anything available tonight?\",\n",
    "    \"Hi!\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    intent = max(doc.cats, key=doc.cats.get)\n",
    "    print(f\"Input: {text}\\n → Predicted Intent: {intent}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5e4b8c-45b9-4578-aa57-baac31162f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.3740736283361912}\n",
      "Epoch 2 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.3690953515470028}\n",
      "Epoch 3 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.35915205255150795}\n",
      "Epoch 4 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.3428703024983406}\n",
      "Epoch 5 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.30612289905548096}\n",
      "Epoch 6 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.2560722716152668}\n",
      "Epoch 7 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.20340811647474766}\n",
      "Epoch 8 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.15808714739978313}\n",
      "Epoch 9 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.09369800833519548}\n",
      "Epoch 10 Loss: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 0.0, 'textcat': 0.07126512727700174}\n",
      "Input: I want to cancel my reservation.\n",
      " → Predicted Intent: cancellation\n",
      "\n",
      "Input: How much is a deluxe room?\n",
      " → Predicted Intent: prices\n",
      "\n",
      "Input: Can I book a suite for Saturday?\n",
      " → Predicted Intent: room_preferences\n",
      "\n",
      "Input: Hey, is there anything available tonight?\n",
      " → Predicted Intent: room_preferences\n",
      "\n",
      "Input: Hi!\n",
      " → Predicted Intent: greeting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Load training data\n",
    "with open('intents.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "train_data = []\n",
    "for intent in data['intents']:\n",
    "    for text in intent['patterns']:\n",
    "        train_data.append((text, {'cats': {intent['tag']: 1}}))\n",
    "\n",
    "# Load spaCy model (base or transformer model)\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # or \"en_core_web_trf\" for transformer-based models\n",
    "\n",
    "# Check if 'textcat' pipe exists, if yes, remove it\n",
    "if \"textcat\" in nlp.pipe_names:\n",
    "    nlp.remove_pipe(\"textcat\")\n",
    "\n",
    "# Add text classification pipeline (no extra params like architecture)\n",
    "textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "\n",
    "# Add intent labels to the 'textcat' component\n",
    "for intent in data['intents']:\n",
    "    textcat.add_label(intent['tag'])\n",
    "\n",
    "# Convert to spaCy Examples\n",
    "train_examples = []\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    train_examples.append(example)\n",
    "\n",
    "# Begin training\n",
    "nlp.initialize(lambda: train_examples)\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_examples)\n",
    "    losses = {}\n",
    "    batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.5))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, drop=0.1, losses=losses)\n",
    "    print(f\"Epoch {epoch+1} Loss: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"hotel_intent_classifiers\")\n",
    "\n",
    "# Test with sample inputs\n",
    "test_texts = [\n",
    "    \"I want to cancel my reservation.\",\n",
    "    \"How much is a deluxe room?\",\n",
    "    \"Can I book a suite for Saturday?\",\n",
    "    \"Hey, is there anything available tonight?\",\n",
    "    \"Hi!\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    intent = max(doc.cats, key=doc.cats.get)\n",
    "    print(f\"Input: {text}\\n → Predicted Intent: {intent}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491d84d-3edc-416d-99da-464e1843b172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
